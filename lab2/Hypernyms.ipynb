{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:56:22.948195Z",
     "start_time": "2020-02-12T17:56:22.944176Z"
    }
   },
   "source": [
    "### Lab 2: Hyponyms and Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.470920Z",
     "start_time": "2020-02-12T14:12:15.640262Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "4\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wikipedia\n",
    "import multiprocessing\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "wikipedia.set_lang(\"ru\")\n",
    "# DATA_PATH_LIST = ['D:','src2','taxonomy-enrichment','data','training_data']\n",
    "DATA_PATH_LIST = ['.']\n",
    "EMBEDDING_MODEL_FILENAME = \"wiki_node2vec.bin\"\n",
    "DATA_PATH=\"/\".join(DATA_PATH_LIST+[\"training_nouns.tsv\"])\n",
    "df = pd.read_csv(DATA_PATH,sep='\\t')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.475780Z",
     "start_time": "2020-02-12T14:12:16.473114Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prestr(x):\n",
    "    return str(x).replace('\\\"','').replace(\"'\",'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.685506Z",
     "start_time": "2020-02-12T14:12:16.477634Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class DefDict(defaultdict):\n",
    "    def __missing__(self, key):\n",
    "        self[key] = key\n",
    "        return key\n",
    "    \n",
    "idx2syns = DefDict(lambda x:x)\n",
    "for val in df.values:\n",
    "    idx2syns[val[0]]=val[1]\n",
    "    try:\n",
    "        pidxs = json.loads(prestr(val[2]))\n",
    "        concp = [el.split(\",\")[0] for el in json.loads(prestr(val[3]))]\n",
    "        idx2syns.update(dict(zip(pidxs,concp)))\n",
    "    except:\n",
    "        print(prestr(val[2]))\n",
    "        print(prestr(val[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:12:34.060220Z",
     "start_time": "2020-02-12T17:12:34.055235Z"
    }
   },
   "source": [
    "### Interactive visualization of hyponyms and hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:11:37.966489Z",
     "start_time": "2020-02-12T17:11:37.931688Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9f50d621734249ab3a9d327a41922e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Draw', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a386d1281f437f84bb4efdf022613a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='МАТЬ', description='String:', placeholder='Query')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description=\"Draw\")\n",
    "query = widgets.Text(\n",
    "    value='МАТЬ',\n",
    "    placeholder='Query',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n",
    "display(button,query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def creategraph(df):\n",
    "    res = []\n",
    "    for row in df.values:\n",
    "        cohyps = row[1].split(\",\")\n",
    "        for idx,cohyp in enumerate(cohyps):\n",
    "            for parent in json.loads(prestr(row[2])):\n",
    "                res.append((row[0]+'-'+str(idx),parent))\n",
    "    return res\n",
    "\n",
    "def graphdraw(b):\n",
    "    print(\"graphdraw\",query.value)\n",
    "    subset = df[df['TEXT'].str.contains(query.value.upper())]\n",
    "    g = nx.DiGraph()\n",
    "    for el in subset.values:\n",
    "        cohyps = el[1].split(\",\")\n",
    "        print(cohyps)\n",
    "        syns = idx2syns[el[0]]\n",
    "        for child in cohyps:\n",
    "            for parent in json.loads(prestr(el[2])):\n",
    "                ed = g.add_edge(child,idx2syns[parent],label=\"is a\")\n",
    "            \n",
    "    plt.figure(figsize=(15,15))\n",
    "    pos = nx.nx_agraph.graphviz_layout(g)\n",
    "    nx.draw(g,with_labels=True,pos=pos)\n",
    "#     edge_labels=nx.draw_networkx_edge_labels(g,pos=pos)\n",
    "    plt.show()\n",
    "button.on_click(graphdraw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T11:38:20.619158Z",
     "start_time": "2020-02-12T11:38:20.614734Z"
    }
   },
   "source": [
    "### Pattern extractor\n",
    "\n",
    "Yargy — библиотека для извлечения структурированной информации из текстов на русском языке. Правила описываются контекстно-свободными грамматиками и словарями ключевых слов. Банк готовых правил для имён, дат, адресов и других сущностей доступен в репозитории Natasha.\n",
    "* https://yargy.readthedocs.io/ru/latest/\n",
    "* http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "* https://github.com/natasha/natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-12T13:09:50.486Z"
    }
   },
   "source": [
    "### Токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.819980Z",
     "start_time": "2020-02-12T14:12:16.708109Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['Ростов', '-', 'на', '-', 'Дону']\n",
      "['Длительностью', '18', 'ч', '.', '10', 'мин', '.']\n",
      "['Яндекс', '.', 'Такси']\n",
      "['π', '≈', '3', '.', '1415']\n",
      "['1', '500', '000', '$']\n",
      "['http', ':', '/', '/', 'vk', '.', 'com']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from yargy.tokenizer import MorphTokenizer\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "text = '''Ростов-на-Дону\n",
    "Длительностью 18ч. 10мин.\n",
    "Яндекс.Такси\n",
    "π ≈ 3.1415\n",
    "1 500 000$\n",
    "http://vk.com\n",
    "'''\n",
    "for line in text.splitlines():\n",
    "    print([_.value for _ in tokenizer(line)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:11:56.582467Z",
     "start_time": "2020-02-12T13:11:56.566175Z"
    }
   },
   "source": [
    "# Газеттир\n",
    "Газеттир нужен для удобной работы с последовательностью слов. Например, можно написать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.844412Z",
     "start_time": "2020-02-12T14:12:16.821582Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from yargy import or_, rule\n",
    "from yargy.predicates import normalized\n",
    "\n",
    "RULE = or_(\n",
    "    rule(normalized('dvd'), '-', normalized('диск')),\n",
    "    rule(normalized('видео'), normalized('файл'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.968622Z",
     "start_time": "2020-02-12T14:12:16.846737Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['Видео', 'файл']\n",
      "['dvd', '-', 'диске']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from yargy import Parser\n",
    "from yargy.pipelines import morph_pipeline\n",
    "\n",
    "\n",
    "RULE = morph_pipeline([\n",
    "    'dvd-диск',\n",
    "    'видео файл',\n",
    "    'видеофильм',\n",
    "    'газета',\n",
    "    'электронный дневник',\n",
    "    'эссе',\n",
    "])\n",
    "\n",
    "parser = Parser(RULE)\n",
    "text = 'Видео файл на dvd-диске'\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:54.576104Z",
     "start_time": "2020-02-12T14:12:54.511149Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['Чеченской', 'республике']\n",
      "['Донецкая', 'народная', 'республика']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from yargy import Parser, rule, and_\n",
    "from yargy.predicates import gram, is_capitalized, dictionary\n",
    "\n",
    "\n",
    "GEO = rule(\n",
    "    and_(\n",
    "        gram('ADJF'),  # так помечается прилагательное, остальные пометки описаны в\n",
    "                       # http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "        is_capitalized()\n",
    "    ),\n",
    "    gram('ADJF').optional().repeatable(),\n",
    "    dictionary({\n",
    "        'федерация',\n",
    "        'республика'\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "parser = Parser(GEO)\n",
    "text = '''\n",
    "В Чеченской республике на день рождения ...\n",
    "Донецкая народная республика провозгласила ...\n",
    "Башня Федерация — одна из самых высоких ...\n",
    "'''\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:13:57.167613Z",
     "start_time": "2020-02-12T13:13:57.159920Z"
    }
   },
   "source": [
    "### Предикаты\n",
    "\n",
    "Предикат — функция, которая принимает на вход токен и возвращает True или False. В Yargy встроено много готовых предикатов. Полный список есть в справочнике. Предикаты комбинируются с помощью and_, or_ и not_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:17.173350Z",
     "start_time": "2020-02-12T14:12:17.136108Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "True\n",
      "True\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from yargy import and_, not_\n",
    "from yargy.tokenizer import MorphTokenizer\n",
    "from yargy.predicates import is_capitalized, eq\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "token = next(tokenizer('Стали'))\n",
    "\n",
    "predicate = is_capitalized()\n",
    "print(predicate(token))\n",
    "\n",
    "predicate = and_(\n",
    "    is_capitalized(),\n",
    "    not_(eq('марки'))\n",
    ")\n",
    "print(predicate(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:15:56.600763Z",
     "start_time": "2020-02-12T13:15:56.596609Z"
    }
   },
   "source": [
    "### Грамматики\n",
    "В Yargy используется специальный DSL для описания грамматик. Любую контекстно-свободную грамматику можно описать с помощью конструкций Питона. Например, есть примитивная грамматика для размеров одежды:\n",
    "\n",
    "KEY -> р. | размер\n",
    "\n",
    "VALUE -> S | M | L\n",
    "\n",
    "SIZE -> KEY VALUE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:14:21.602988Z",
     "start_time": "2020-02-12T14:14:21.589310Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIZE -> KEY VALUE\n",
       "KEY -> 'р' '.' | 'размер'\n",
       "VALUE -> 'S' | 'M' | 'L' | 'XS'\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yargy import rule, or_\n",
    "\n",
    "\n",
    "KEY = or_(\n",
    "    rule('р', '.'),\n",
    "    rule('размер')\n",
    ").named('KEY')\n",
    "VALUE = or_(\n",
    "    rule('S'),\n",
    "    rule('M'),\n",
    "    rule('L'),\n",
    "    rule('XS'),\n",
    ").named('VALUE')\n",
    "SIZE = rule(\n",
    "    KEY,\n",
    "    VALUE\n",
    ").named('SIZE')\n",
    "SIZE.normalized.as_bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:14:27.723857Z",
     "start_time": "2020-02-12T14:14:27.662113Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['размер', 'M']\n",
      "['размер', 'XS']\n"
     ]
    }
   ],
   "source": [
    "parser = Parser(\n",
    "    SIZE\n",
    ")\n",
    "text = 'размер M; размер A; размер XS;'\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.308726Z",
     "start_time": "2020-02-12T14:12:17.354354Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from yargy import Parser, rule, and_, or_, not_\n",
    "from yargy.interpretation import fact, attribute\n",
    "from yargy.predicates import gram, is_capitalized, dictionary, eq\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.323139Z",
     "start_time": "2020-02-12T14:12:19.310769Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "START = rule(\n",
    "    or_(\n",
    "        rule(gram('ADJF')),\n",
    "        rule(gram('NOUN'))\n",
    "    ).optional(),\n",
    "    gram('NOUN')\n",
    ")\n",
    "\n",
    "START_S = or_(\n",
    "    eq('такой'),\n",
    "    eq('такие'),\n",
    ")\n",
    "\n",
    "KAK = eq('как')\n",
    "INCLUDING = or_(\n",
    "    or_(\n",
    "        eq('в'),\n",
    "        eq('том'),\n",
    "        eq('числе'),\n",
    "    ),\n",
    "    eq('включающий'),\n",
    "    or_(\n",
    "        eq('включающий'),\n",
    "        eq('в'),\n",
    "        eq('себя'),\n",
    "    ),\n",
    "    or_(\n",
    "        eq('включающие'),\n",
    "        eq('в'),\n",
    "        eq('себя'),\n",
    "    ),\n",
    "    eq('включающие'),\n",
    "    eq('особенно'),\n",
    "\n",
    ")\n",
    "\n",
    "MID_S = or_(\n",
    "    rule(\n",
    "        or_(\n",
    "            eq('такой'),\n",
    "            eq('такие'),\n",
    "        ),\n",
    "        eq('как')\n",
    "    )\n",
    ")\n",
    "ATAKJE = rule(\n",
    "    eq(','),\n",
    "    eq('а'),\n",
    "    eq('также')\n",
    ")\n",
    "\n",
    "MID = or_(\n",
    "    rule(\n",
    "        eq('это')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—'),\n",
    "        eq('это')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—'),\n",
    "        not_(eq('км'))\n",
    "    ),\n",
    "    rule(\n",
    "        or_(\n",
    "            eq('и'),\n",
    "            eq('или'),\n",
    "        ),\n",
    "        eq('другие')\n",
    "    )\n",
    ")\n",
    "\n",
    "END = or_(\n",
    "    rule(\n",
    "        gram('NOUN'),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('ADJF').repeatable(),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('ADJF'),\n",
    "        gram('ADJF').repeatable(),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('NOUN').repeatable(),\n",
    "        gram('ADJF'),\n",
    "        gram('NOUN').repeatable()\n",
    "    ),\n",
    "    rule(\n",
    "        gram('NOUN').repeatable()\n",
    "    )\n",
    ")\n",
    "\n",
    "Item = fact(\n",
    "    'Item',\n",
    "    [attribute('titles').repeatable()]\n",
    ")\n",
    "\n",
    "\n",
    "IGNORE = rule(\n",
    "    '(',\n",
    "    not_(eq(')')).repeatable(),\n",
    "    ')'\n",
    ")\n",
    "\n",
    "ITEM = rule(\n",
    "    IGNORE.interpretation(\n",
    "        Item.titles\n",
    "    ),\n",
    "    eq(',').optional() \n",
    ").repeatable().interpretation(\n",
    "    Item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.434702Z",
     "start_time": "2020-02-12T14:12:19.324707Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_hyperonyms(main_word):\n",
    "    HYPONYM = eq(utils.deaccent(main_word))\n",
    "    RULE = or_(\n",
    "        rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "        rule(HYPONYM, MID, END),\n",
    "        rule(START_S, END, KAK, HYPONYM),\n",
    "        rule(END, INCLUDING, HYPONYM)\n",
    "    )\n",
    "    parser = Parser(RULE) \n",
    "    text = utils.deaccent(wikipedia.summary(main_word))\n",
    "    print(text)\n",
    "    text = re.sub(r'\\(.+?\\)', '', text)\n",
    "    text = text.lower().replace('* сергии радонежскии* ', '')\n",
    "    for idx, match in enumerate(parser.findall(text.lower())):\n",
    "        k = [_.value for _ in match.tokens]\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:22.648500Z",
     "start_time": "2020-02-12T14:12:19.437840Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Банан — название съедобных плодов культивируемых растении рода Банан (Musa); обычно под таковыми понимают Musa acuminata и Musa × paradisiaca, а также Musa balbisiana, Musa fehi, Musa troglodytarum и ряд других. Также бананами могут называть плоды Ensete ventricosum (строго говоря, являющегося представителем другого рода семеиства Банановые). С ботаническои точки зрения банан является ягодои, многосеменнои и толстокожеи. У культурных форм часто отсутствуют семена, ненужные при вегетативном размножении. Плоды имеют длину 6—30 см и диаметр 2—5 см. Соплодия могут состоять из 300 плодов и иметь массу до 50—60 кг.\n",
      "Бананы — одна из древнеиших пищевых культур, а для тропических стран важнеишее пищевое растение и главная статья экспорта. Спелые бананы широко употребляются в пищу по всему миру, их используют при приготовлении большого количества блюд. Помимо употребления в свежем виде, в кухне некоторых народов бананы могут зажариваться, или вариться как в очищенном, так и в неочищенном виде. Их также сушат, консервируют, используют для приготовления банановои муки, мармелада, сиропов, вин. Бананы применяются также в качестве корма для скота. Запах бананов определяют изовалерианово-изоамиловыи и уксусно-изоамиловыи эфиры. Выращиваются в тропических и субтропических раионах с жарким влажным климатом. Существует большое число сортов съедобных видов банана.\n",
      "Размер, цвет и форма могут значительно различаться в зависимости от вида или сорта, но чаще всего они имеют продолговатую цилиндрическую или трехгранную форму, выпрямленную либо закругленную. Длина плода варьирует в пределах от 3 до 40 см, толщина — от 2 до 8 см. Цвет кожицы может быть желтым, зеленым, красным или даже серебристым. Мякоть белая, кремовая, желтая или оранжевая. В незрелом состоянии она твердая и клеикая, но по мере созревания становится мягкои и сочнои.\n",
      "Во многих странах бананы являются одним из основных источников питания — например, только в Эквадоре годовое потребление этого продукта составляет 73,8 кг на душу населения (для сравнения, в России этот показатель равен 7,29 кг). Существенную долю потребления бананы также составляют в Бурунди (189,4 кг), Самоа (85,0 кг), Коморских Островах (77,8 кг) и на Филиппинах (40,6 кг).\n",
      "['банан', '—', 'название', 'съедобных', 'плодов']\n"
     ]
    }
   ],
   "source": [
    "get_hyperonyms(\"банан\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (deadline 19.02.2020 24:00)\n",
    "* Find your name on the spreadsheet https://docs.google.com/spreadsheets/d/1RR2I6toCkebbGU1UK83HS70Ru_l0_o-nnZIHyiFB0No/edit?usp=sharing. In opposite of your name there are 24 words of hyponyms, you have to insert five corresponding hypernyms next to them. Examples of hyponyms and hyperonyms relationship you can find above in the current Jupiter notebook.\n",
    "* Find for each pair of hyponyms and hypernyms a corresponding snippet of a text with their mentions. The source of the text can be any free resources, e.g., Wikipedia, Google, Yandex, others. You should save the snippets and their URLs within the lab2 folder in your NLP git-repo with .csv file-extension in a single file.\n",
    "\n",
    "#### Task 2 (deadline 26.02.2020 24:00)\n",
    "* It would be best if you created a pandas DataFrame of the texts from the previous task. And apply to the DataFrame the function 'get_hyperonyms,' which must return the list of the corresponding hypernyms from the text automatically. If there are errors or misses, you should fix them in the code for your case of the 24 words. Nevertheless, it is strictly prohibited to use hard coding. Save your notebook with parser code within the lab2 folder in your NLP git-repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYPONYM</th>\n",
       "      <th>HYPERONYM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ГЕККОН</td>\n",
       "      <td>ящерица, чешуйчатый, пресмыкающиеся, животное,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ГЕЛЬ</td>\n",
       "      <td>желеобразное вещество, косметика, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ГЕОРГИН</td>\n",
       "      <td>растение, цветы, сложноцветный цветок, трава, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ГЕОФАК</td>\n",
       "      <td>факультет, , специальность, структурное подраз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ГЕРИАТРИЯ</td>\n",
       "      <td>геронтология, наука, изучение болезней, знание...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ГЕРМАНИЗАЦИЯ</td>\n",
       "      <td>распространение языка, распространения культур...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ГЕРМЕТИК</td>\n",
       "      <td>, материал, смазка, замазка,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ГЕРОНТОЛОГ</td>\n",
       "      <td>врач, специалист, доктор, человек, профессия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ГЕСТАПОВЕЦ</td>\n",
       "      <td>сотрудник гестапо, человек, тайная военная пол...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ГИГИЕНИСТ</td>\n",
       "      <td>человек, врач, специалист, доктор, профессия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ГИДРАТАЦИЯ</td>\n",
       "      <td>сольватация, соединение, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ГИДРИД</td>\n",
       "      <td>соединение водорода с металлами, химический эл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ГИДРОЛИЗ</td>\n",
       "      <td>разложение, сольволиз, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ГИДРОПОНИКА</td>\n",
       "      <td>рост, выращивание растений, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ГИДРОЦИКЛ</td>\n",
       "      <td>транспорт, мотоцикл, аквабайк, авто, водные лыжи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ГИПЕРБОЛА</td>\n",
       "      <td>график, кривая, геометрия, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ГИПЕРКАР</td>\n",
       "      <td>авто, машина, транспорт, суперкар, средство пе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ГИПЕРРЕАЛИЗМ</td>\n",
       "      <td>направление в исскустве, современное исскуство...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ГИПЕРТЕРМИЯ</td>\n",
       "      <td>перегревание, повышение температуры тела, нако...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ГИПЕРТРОФИЯ</td>\n",
       "      <td>увеличение органа, рост органа, болезнь, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ГИПОТОНИК</td>\n",
       "      <td>больной, человек, пациент, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ГИПЮР</td>\n",
       "      <td>ткань, материал, кружева, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ГИРЯ</td>\n",
       "      <td>спорт товар, предмет, металлический груз, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ГИЧКА</td>\n",
       "      <td>шлюпка, судно, лодка, транспорт, средство пере...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         HYPONYM                                          HYPERONYM\n",
       "0         ГЕККОН  ящерица, чешуйчатый, пресмыкающиеся, животное,...\n",
       "1           ГЕЛЬ             желеобразное вещество, косметика, , , \n",
       "2        ГЕОРГИН  растение, цветы, сложноцветный цветок, трава, ...\n",
       "3         ГЕОФАК  факультет, , специальность, структурное подраз...\n",
       "4      ГЕРИАТРИЯ  геронтология, наука, изучение болезней, знание...\n",
       "5   ГЕРМАНИЗАЦИЯ  распространение языка, распространения культур...\n",
       "6       ГЕРМЕТИК                      , материал, смазка, замазка, \n",
       "7     ГЕРОНТОЛОГ       врач, специалист, доктор, человек, профессия\n",
       "8     ГЕСТАПОВЕЦ  сотрудник гестапо, человек, тайная военная пол...\n",
       "9      ГИГИЕНИСТ       человек, врач, специалист, доктор, профессия\n",
       "10    ГИДРАТАЦИЯ                      сольватация, соединение, , , \n",
       "11        ГИДРИД  соединение водорода с металлами, химический эл...\n",
       "12      ГИДРОЛИЗ                        разложение, сольволиз, , , \n",
       "13   ГИДРОПОНИКА                   рост, выращивание растений, , , \n",
       "14     ГИДРОЦИКЛ   транспорт, мотоцикл, аквабайк, авто, водные лыжи\n",
       "15     ГИПЕРБОЛА                      график, кривая, геометрия, , \n",
       "16      ГИПЕРКАР  авто, машина, транспорт, суперкар, средство пе...\n",
       "17  ГИПЕРРЕАЛИЗМ  направление в исскустве, современное исскуство...\n",
       "18   ГИПЕРТЕРМИЯ  перегревание, повышение температуры тела, нако...\n",
       "19   ГИПЕРТРОФИЯ        увеличение органа, рост органа, болезнь, , \n",
       "20     ГИПОТОНИК                      больной, человек, пациент, , \n",
       "21         ГИПЮР                       ткань, материал, кружева, , \n",
       "22          ГИРЯ       спорт товар, предмет, металлический груз, , \n",
       "23         ГИЧКА  шлюпка, судно, лодка, транспорт, средство пере..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homework_data = pd.read_csv('words_2.csv')\n",
    "\n",
    "homework_data\n",
    "\n",
    "\n",
    "# for key in keys:\n",
    "#     for word in \n",
    "\n",
    "# for row in homework_data.iterrows():\n",
    "#     print(row[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_text(word): \n",
    "    return utils.deaccent(wikipedia.summary(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "# Search in wiki only HYPERONYMs\n",
    "for hypo, hypers in zip(list(homework_data['HYPONYM']), list(homework_data['HYPERONYM'])):\n",
    "    hypers = list(map(lambda x: x.strip(), hypers.split(\", \")))\n",
    "    for hyper in hypers:\n",
    "        tmp = {}\n",
    "        tmp[\"hypo\"] = hypo\n",
    "        if hyper == \"\":\n",
    "            continue\n",
    "        tmp[\"key\"] = hyper\n",
    "        try:\n",
    "            tmp[\"text\"] = find_text(hyper)\n",
    "        except:\n",
    "            tmp[\"text\"] = \"\"\n",
    "            print(\"error\")\n",
    "        result.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hypo': 'ГЕККОН',\n",
       " 'key': 'ящерица',\n",
       " 'text': 'Ящерицы (лат. Lacertilia, ранее Sauria) — подотряд пресмыкающихся из отряда чешуичатых по традиционнои систематике. Подотряд ящериц не является биологически четко определяемои категориеи, а включает всех чешуичатых, кроме змеи и (традиционно) двуходок. С точки зрения кладистическои классификации ящерицы — это парафилетическая группа, которая должна быть расформирована на несколько меньших монофилетических групп, либо включить в себя исключенные из нее подотряды змеи и двуходок. К примеру, змеи являются потомками ящериц и генетически тесно связаны с игуанообразными и веретеницеобразными ящерицами, образуя вместе с ними общую кладу Toxicofera. Таким образом, по кладистическим принципам змеи могут считаться ящерицами, и лишь условно выделяются традиционными систематиками в отдельныи подотряд. По данным базы The Reptile Database, по состоянию на июнь 2017 года известны 6332 вида ящериц.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = \"text_HYPONYM.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=[\"hypo\", \"key\", \"text\"])\n",
    "        for data in result:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperonyms2(main_word, text):\n",
    "    HYPONYM = eq(utils.deaccent(main_word))\n",
    "    RULE = or_(\n",
    "        rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "        rule(HYPONYM, MID, END),\n",
    "        rule(START_S, END, KAK, HYPONYM),\n",
    "        rule(END, INCLUDING, HYPONYM)\n",
    "    )\n",
    "    parser = Parser(RULE) \n",
    "#     text = utils.deaccent(wikipedia.summary(main_word))\n",
    "#     print(text)\n",
    "    text = re.sub(r'\\(.+?\\)', '', text)\n",
    "#     text = text.lower().replace('* сергии радонежскии* ', '')\n",
    "    for idx, match in enumerate(parser.findall(text.lower())):\n",
    "        k = [_.value for _ in match.tokens]\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гиперонимы для слова:  ящерица\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  чешуйчатый\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  пресмыкающиеся\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  животное\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  рептилия\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  желеобразное вещество\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  косметика\n",
      "\n",
      "\n",
      "['косметика', '—', 'учение']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  растение\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  цветы\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  сложноцветный цветок\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  трава\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  зелень\n",
      "\n",
      "\n",
      "['зелень', '—', 'свежие', 'молодые', 'побеги', 'растении']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  факультет\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  специальность\n",
      "\n",
      "\n",
      "['специальность', '—', 'комплекс']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  структурное подразделение\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  геронтология\n",
      "\n",
      "\n",
      "['геронтология', '—', 'наука']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  наука\n",
      "\n",
      "\n",
      "['наука', '—', 'область', 'человеческои', 'деятельности']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  изучение болезней\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  знание\n",
      "\n",
      "\n",
      "['знание', '—', 'результат', 'познавательнои', 'деятельности']\n",
      "['знание', '—', 'это', 'образ', 'реальности', 'субъекта', 'в', 'форме', 'понятии', 'и', 'представлении']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  лечение\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  распространение языка\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  распространения культуры\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  материал\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  смазка\n",
      "Пусто\n",
      "Гиперонимы для слова:  замазка\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  врач\n",
      "\n",
      "\n",
      "['врач', '—', 'человек']\n",
      "['врач', '—', 'доктор']\n",
      "['врач', '—', 'лицо', 'с']\n",
      "['врач', '—', 'имеет', 'среднее', 'медицинское', 'образование']\n",
      "['врач', '—', 'руководитель', 'медицинского', 'учреждения']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  специалист\n",
      "\n",
      "\n",
      "['специалист', '—', 'квалификация']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  доктор\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  человек\n",
      "\n",
      "\n",
      "['человек', '—', 'общественное', 'существо']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  профессия\n",
      "\n",
      "\n",
      "['профессия', '—', 'род', 'трудовои', 'деятельности', 'человека']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  сотрудник гестапо\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  человек\n",
      "\n",
      "\n",
      "['человек', '—', 'общественное', 'существо']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  тайная военная полиция\n",
      "Пусто\n",
      "Гиперонимы для слова:  эсэсовец\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  профессия\n",
      "\n",
      "\n",
      "['профессия', '—', 'род', 'трудовои', 'деятельности', 'человека']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  человек\n",
      "\n",
      "\n",
      "['человек', '—', 'общественное', 'существо']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  врач\n",
      "\n",
      "\n",
      "['врач', '—', 'человек']\n",
      "['врач', '—', 'доктор']\n",
      "['врач', '—', 'лицо', 'с']\n",
      "['врач', '—', 'имеет', 'среднее', 'медицинское', 'образование']\n",
      "['врач', '—', 'руководитель', 'медицинского', 'учреждения']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  специалист\n",
      "\n",
      "\n",
      "['специалист', '—', 'квалификация']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  доктор\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  профессия\n",
      "\n",
      "\n",
      "['профессия', '—', 'род', 'трудовои', 'деятельности', 'человека']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  сольватация\n",
      "\n",
      "\n",
      "['сольватация', '—', 'электростатическое', 'взаимодеиствие']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  соединение\n",
      "\n",
      "\n",
      "['соединение', '—', 'процесс', 'изготовления', 'изделия', 'из', 'деталеи']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  соединение водорода с металлами\n",
      "Пусто\n",
      "Гиперонимы для слова:  химический элемент\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  разложение\n",
      "Пусто\n",
      "Гиперонимы для слова:  сольволиз\n",
      "\n",
      "\n",
      "['сольволиз', '—', 'реакция', 'обменного', 'разложения']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  рост\n",
      "Пусто\n",
      "Гиперонимы для слова:  выращивание растений\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  транспорт\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  мотоцикл\n",
      "\n",
      "\n",
      "['мотоцикл', '—', 'двухколесное', 'транспортное', 'средство']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  аквабайк\n",
      "\n",
      "\n",
      "['аквабаик', '—', 'общее', 'название']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  авто\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  водные лыжи\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  график\n",
      "Пусто\n",
      "Гиперонимы для слова:  кривая\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  геометрия\n",
      "\n",
      "\n",
      "['геометрия', '—', 'раздел', 'математики']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  авто\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  машина\n",
      "\n",
      "\n",
      "['машина', '—', 'техническое', 'приспособление']\n",
      "['машина', '—', 'механизм']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  транспорт\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  суперкар\n",
      "\n",
      "\n",
      "['суперкар', '—', 'условно', 'выделяемыи', 'подкласс']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  средство передвижения\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  направление в исскустве\n",
      "Пусто\n",
      "Гиперонимы для слова:  современное исскуство\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  исскуство\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  натурализм\n",
      "\n",
      "\n",
      "['натурализм', '—', 'поздняя', 'стадия', 'развития', 'реализма', 'в', 'литературе', 'конца']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  живопись\n",
      "\n",
      "\n",
      "['живопись', '—', 'вид', 'изобразительного', 'искусства']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  перегревание\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  повышение температуры тела\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  накопление тепла\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  лечение\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  терапия\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  увеличение органа\n",
      "Пусто\n",
      "Гиперонимы для слова:  рост органа\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  болезнь\n",
      "\n",
      "\n",
      "['болезнь', '—', 'это', 'состояние', 'организма']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  больной\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  человек\n",
      "\n",
      "\n",
      "['человек', '—', 'общественное', 'существо']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  пациент\n",
      "\n",
      "\n",
      "['пациент', '—', 'человек']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  ткань\n",
      "\n",
      "\n",
      "['ткань', '—', 'текстильное', 'полотно']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  материал\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  кружева\n",
      "\n",
      "\n",
      "['кружева', '—', 'платье']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  спорт товар\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  предмет\n",
      "Пусто\n",
      "Гиперонимы для слова:  металлический груз\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  шлюпка\n",
      "\n",
      "\n",
      "['шлюпка', '—', 'общее', 'название', 'малого']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  судно\n",
      "\n",
      "\n",
      "['судно', '—', 'плавучее', 'сооружение']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  лодка\n",
      "\n",
      "\n",
      "['лодка', '—', 'небольшое', 'судно']\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  транспорт\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Гиперонимы для слова:  средство передвижения\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for data in result:\n",
    "    print('Гиперонимы для слова: ', data[\"key\"])\n",
    "    if data[\"text\"] == \"\":\n",
    "        print(\"Пусто\")\n",
    "        continue\n",
    "    print('\\n')\n",
    "    get_hyperonyms2(data[\"key\"], data[\"text\"])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "from google import google\n",
    "\n",
    "class GoogleSearch(object):\n",
    "    def __init__(self, hypo, hyper, num_page):\n",
    "        self.hypo = hypo\n",
    "        self.hyper = hyper\n",
    "        self.num_page = num_page\n",
    "        self.res = None\n",
    "        \n",
    "    def get_text(self):\n",
    "        if  self.res is not None:\n",
    "            return self.res.description\n",
    "        return None\n",
    "    \n",
    "    def get_link(self):\n",
    "        if  self.res is not None:\n",
    "            return self.res.link\n",
    "        return None\n",
    "    \n",
    "    def get_google_link(self):\n",
    "        if  self.res is not None:\n",
    "            return self.res.google_link\n",
    "        return None\n",
    "    \n",
    "    def find_text(self):\n",
    "        search_results = google.search(self.hypo + \" \" + self.hyper, self.num_page)\n",
    "        print(self.hypo + \" \" + self.hyper)\n",
    "        print(\"Search result count: \", len(search_results))\n",
    "        for res in search_results:\n",
    "            parser = HyperParser(self.hypo, self.hyper, res.description)\n",
    "            parser.get_hyperonyms3()            \n",
    "            if len(parser.hyper_text) > 0:                \n",
    "                self.res = res\n",
    "                "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "from yargy.predicates import is_single\n",
    "\n",
    "class HyperParser(object):\n",
    "    def __init__(self, hypo, hyper, text):\n",
    "        self.hypo = hypo.capitalize()\n",
    "        self.hyper = hyper\n",
    "        self.text = text\n",
    "        self.hyper_text = \"\"\n",
    "        \n",
    "    def get_hyperonyms3(self):\n",
    "        \n",
    "        predicate = is_single()\n",
    "        \n",
    "        HYPONYM = or_(\n",
    "            rule(eq(utils.deaccent(self.hypo))),\n",
    "            rule(predicate(self.hypo))            \n",
    "        )\n",
    "        \n",
    "        RULE = or_(\n",
    "            rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "            # rule(HYPONYM, ATAKJE, START, MID, self.hyper),\n",
    "            rule(HYPONYM, MID, END),\n",
    "            # rule(HYPONYM, MID, self.hyper),\n",
    "            rule(START_S, END, KAK, HYPONYM),\n",
    "            # rule(self.hyper, START_S, END, KAK, HYPONYM),\n",
    "            rule(END, INCLUDING, HYPONYM),\n",
    "            # rule(self.hyper, INCLUDING, HYPONYM)\n",
    "        )\n",
    "        parser = Parser(RULE) \n",
    "        print(self.hypo)\n",
    "    #     text = utils.deaccent(wikipedia.summary(main_word))\n",
    "    #     print(text)\n",
    "        _text = re.sub(r'\\(.+?\\)', '', self.text)\n",
    "        print(_text)\n",
    "        for idx, match in enumerate(parser.findall(_text.lower())):\n",
    "            print(match)\n",
    "            k = [_.value for _ in match.tokens]\n",
    "            if k is not None:\n",
    "                print(k)\n",
    "                self.hyper_text = k    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ГЕККОН ящерица\n",
      "Search result count:  9\n",
      "Геккон\n",
      "Гекко́ны, или гекко́новые, или цепкопа́лые , — обширное семейство небольших и средней величины весьма своеобразных ящериц, ...\n",
      "Геккон\n",
      "Геккон токи  — ящерица из семейства гекконов. Содержание. 1 Описание; 2 Ареал и места обитания; 3 Питание; 4 Размножение ...\n",
      "Геккон\n",
      "Эти маленькие тропические ящерицы вызывают наше восхищение своим умением удерживаться практически на любой поверхности. Гекконы ...\n",
      "Геккон\n",
      "Читайте самые интересные и обсуждаемые посты по темам Геккон и Ящерица. Личный опыт, познавательные статьи, забавные фото и видео.\n",
      "Геккон\n",
      "Очистить фильтры. Похожие изображения: ящерица рептилия животных зеленый тварь. 376 Бесплатные фото Геккон. Геккон, Рептилия, Террариум ...\n",
      "Геккон\n",
      "Итак, хочу представить вашему вниманию одну из самых очаровательных ящериц семейства гекконов — сцинкового геккона .\n",
      "Геккон\n",
      "2013 ж. 27 нау. - Улыбчивый красавец-геккон ... Эти маленькие тропические ящерицы вызывают наше восхищение своим ... геккон, ящерица, рептилия.\n",
      "Геккон\n",
      "Закажите геккона и террариум по доступной цене в интернет-магазине ... Это компактные и милые ящерицы, которые точно завоюют ваше сердце.\n",
      "Геккон\n",
      "Скачать стоковое фото ящерица геккона ✓ популярный фотобанк ✓ доступные цены ✓ миллионы роялти-фри фотографий, изображений и картинок в ...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tmp = GoogleSearch(\"ГЕККОН\", \"ящерица\", 1)\n",
    "tmp.find_text()\n",
    "tmp.get_text()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "ГЕККОН ящерица\n",
      "Search result count:  9\n",
      "ГЕККОН чешуйчатый\n",
      "Search result count:  9\n",
      "ГЕККОН пресмыкающиеся\n",
      "Search result count:  7\n",
      "ГЕККОН животное\n",
      "Search result count:  8\n",
      "ГЕККОН рептилия\n",
      "Search result count:  8\n",
      "ГЕЛЬ желеобразное вещество\n",
      "Search result count:  9\n",
      "ГЕЛЬ косметика\n",
      "Search result count:  9\n",
      "ГЕОРГИН растение\n",
      "Search result count:  10\n",
      "ГЕОРГИН цветы\n",
      "Search result count:  8\n",
      "ГЕОРГИН сложноцветный цветок\n",
      "Search result count:  9\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-67ded2e1f646>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-d315891695d5>\u001b[0m in \u001b[0;36mfind_text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_page\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypo\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Search result count: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/google/modules/standard_search.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, pages, lang, area, ncr, void, time_period, sort_by_date, first_page)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mdivs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"g\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains_replacement_characters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m              self.builder.prepare_markup(\n\u001b[0;32m--> 322\u001b[0;31m                  markup, from_encoding, exclude_encodings=exclude_encodings)):\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mprepare_markup\u001b[0;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mtry_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0muser_specified_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_declared_encoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         dammit = UnicodeDammit(markup, try_encodings, is_html=True,\n\u001b[0;32m--> 326\u001b[0;31m                                exclude_encodings=exclude_encodings)\n\u001b[0m\u001b[1;32m    327\u001b[0m         yield (dammit.markup, dammit.original_encoding,\n\u001b[1;32m    328\u001b[0m                \u001b[0mdammit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclared_html_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, override_encodings, smart_quotes_to, is_html, exclude_encodings)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mencodings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# encoding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchardet_dammit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_usable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchardet_encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/bs4/dammit.py\u001b[0m in \u001b[0;36mchardet_dammit\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m#import chardet.constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#chardet.constants._debug = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/chardet/__init__.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(byte_str)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUniversalDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/chardet/universaldetector.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLatin1Prober\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mprober\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_charset_probers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mProbingState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFOUND_IT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m                     self.result = {'encoding': prober.charset_name,\n\u001b[1;32m    213\u001b[0m                                    \u001b[0;34m'confidence'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/chardet/charsetgroupprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprober\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/chardet/sbcharsetprober.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, byte_str)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keep_english_letter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mbyte_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_international_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbyte_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/master_degree/nlp/nlpCourse/venv/lib/python3.7/site-packages/chardet/charsetprober.py\u001b[0m in \u001b[0;36mfilter_international_words\u001b[0;34m(buf)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# the end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         words = re.findall(b'[a-zA-Z]*[\\x80-\\xFF]+[a-zA-Z]*[^a-zA-Z\\x80-\\xFF]?',\n\u001b[0;32m---> 87\u001b[0;31m                            buf)\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "homework_data = pd.read_csv('words_2.csv')\n",
    "\n",
    "homework_data\n",
    "\n",
    "result = []\n",
    "for hypo, hypers in zip(list(homework_data['HYPONYM']), list(homework_data['HYPERONYM'])):\n",
    "    hypers = list(map(lambda x: x.strip(), hypers.split(\", \")))\n",
    "    for hyper in hypers:\n",
    "        tmp = {}\n",
    "        pair = hypo + \" \" + hyper\n",
    "        tmp[\"hypo\"] = hypo\n",
    "        if hyper == \"\":\n",
    "            continue\n",
    "        tmp[\"key\"] = hyper\n",
    "        search = GoogleSearch(hypo, hyper, 1)\n",
    "        try:\n",
    "            search.find_text()\n",
    "            if search.get_text() is not None:\n",
    "                tmp[\"text\"] = search.get_text()\n",
    "                tmp[\"link\"] = search.get_link()\n",
    "                tmp[\"google_link\"] = search.get_google_link()                \n",
    "        except Exception as err:\n",
    "            tmp[\"text\"] = \"\"\n",
    "            tmp[\"link\"] = search.get_link()\n",
    "            tmp[\"google_link\"] = search.get_google_link()                \n",
    "            print(pair)\n",
    "            print(err)\n",
    "        result.append(tmp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'hypo': 'ГЕККОН', 'key': 'ящерица'}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "result[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = \"text_HYPONYM33.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=[\"hypo\", \"key\", \"text\", \"link\", \"google link\"])\n",
    "        for data in result:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}