{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:56:22.948195Z",
     "start_time": "2020-02-12T17:56:22.944176Z"
    }
   },
   "source": [
    "### Lab 2: Hyponyms and Hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.470920Z",
     "start_time": "2020-02-12T14:12:15.640262Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wikipedia\n",
    "import multiprocessing\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual,widgets\n",
    "from IPython.display import display\n",
    "import json\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(num_cores)\n",
    "wikipedia.set_lang(\"ru\")\n",
    "# DATA_PATH_LIST = ['D:','src2','taxonomy-enrichment','data','training_data']\n",
    "DATA_PATH_LIST = ['.']\n",
    "EMBEDDING_MODEL_FILENAME = \"wiki_node2vec.bin\"\n",
    "DATA_PATH=\"/\".join(DATA_PATH_LIST+[\"training_nouns.tsv\"])\n",
    "df = pd.read_csv(DATA_PATH,sep='\\t')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.475780Z",
     "start_time": "2020-02-12T14:12:16.473114Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prestr(x):\n",
    "    return str(x).replace('\\\"','').replace(\"'\",'\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.685506Z",
     "start_time": "2020-02-12T14:12:16.477634Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class DefDict(defaultdict):\n",
    "    def __missing__(self, key):\n",
    "        self[key] = key\n",
    "        return key\n",
    "    \n",
    "idx2syns = DefDict(lambda x:x)\n",
    "for val in df.values:\n",
    "    idx2syns[val[0]]=val[1]\n",
    "    try:\n",
    "        pidxs = json.loads(prestr(val[2]))\n",
    "        concp = [el.split(\",\")[0] for el in json.loads(prestr(val[3]))]\n",
    "        idx2syns.update(dict(zip(pidxs,concp)))\n",
    "    except:\n",
    "        print(prestr(val[2]))\n",
    "        print(prestr(val[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:12:34.060220Z",
     "start_time": "2020-02-12T17:12:34.055235Z"
    }
   },
   "source": [
    "### Interactive visualization of hyponyms and hypernyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T17:11:37.966489Z",
     "start_time": "2020-02-12T17:11:37.931688Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "button = widgets.Button(description=\"Draw\")\n",
    "query = widgets.Text(\n",
    "    value='МАТЬ',\n",
    "    placeholder='Query',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n",
    "display(button,query)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def creategraph(df):\n",
    "    res = []\n",
    "    for row in df.values:\n",
    "        cohyps = row[1].split(\",\")\n",
    "        for idx,cohyp in enumerate(cohyps):\n",
    "            for parent in json.loads(prestr(row[2])):\n",
    "                res.append((row[0]+'-'+str(idx),parent))\n",
    "    return res\n",
    "\n",
    "def graphdraw(b):\n",
    "    print(\"graphdraw\",query.value)\n",
    "    subset = df[df['TEXT'].str.contains(query.value.upper())]\n",
    "    g = nx.DiGraph()\n",
    "    for el in subset.values:\n",
    "        cohyps = el[1].split(\",\")\n",
    "        print(cohyps)\n",
    "        syns = idx2syns[el[0]]\n",
    "        for child in cohyps:\n",
    "            for parent in json.loads(prestr(el[2])):\n",
    "                ed = g.add_edge(child,idx2syns[parent],label=\"is a\")\n",
    "            \n",
    "    plt.figure(figsize=(15,15))\n",
    "    pos = nx.nx_agraph.graphviz_layout(g)\n",
    "    nx.draw(g,with_labels=True,pos=pos)\n",
    "#     edge_labels=nx.draw_networkx_edge_labels(g,pos=pos)\n",
    "    plt.show()\n",
    "button.on_click(graphdraw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T11:38:20.619158Z",
     "start_time": "2020-02-12T11:38:20.614734Z"
    }
   },
   "source": [
    "### Pattern extractor\n",
    "\n",
    "Yargy — библиотека для извлечения структурированной информации из текстов на русском языке. Правила описываются контекстно-свободными грамматиками и словарями ключевых слов. Банк готовых правил для имён, дат, адресов и других сущностей доступен в репозитории Natasha.\n",
    "* https://yargy.readthedocs.io/ru/latest/\n",
    "* http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "* https://github.com/natasha/natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-02-12T13:09:50.486Z"
    }
   },
   "source": [
    "### Токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.819980Z",
     "start_time": "2020-02-12T14:12:16.708109Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ростов', '-', 'на', '-', 'Дону']\n",
      "['Длительностью', '18', 'ч', '.', '10', 'мин', '.']\n",
      "['Яндекс', '.', 'Такси']\n",
      "['π', '≈', '3', '.', '1415']\n",
      "['1', '500', '000', '$']\n",
      "['http', ':', '/', '/', 'vk', '.', 'com']\n"
     ]
    }
   ],
   "source": [
    "from yargy.tokenizer import MorphTokenizer\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "text = '''Ростов-на-Дону\n",
    "Длительностью 18ч. 10мин.\n",
    "Яндекс.Такси\n",
    "π ≈ 3.1415\n",
    "1 500 000$\n",
    "http://vk.com\n",
    "'''\n",
    "for line in text.splitlines():\n",
    "    print([_.value for _ in tokenizer(line)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:11:56.582467Z",
     "start_time": "2020-02-12T13:11:56.566175Z"
    }
   },
   "source": [
    "# Газеттир\n",
    "Газеттир нужен для удобной работы с последовательностью слов. Например, можно написать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.844412Z",
     "start_time": "2020-02-12T14:12:16.821582Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from yargy import or_, rule\n",
    "from yargy.predicates import normalized\n",
    "\n",
    "RULE = or_(\n",
    "    rule(normalized('dvd'), '-', normalized('диск')),\n",
    "    rule(normalized('видео'), normalized('файл'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:16.968622Z",
     "start_time": "2020-02-12T14:12:16.846737Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Видео', 'файл']\n",
      "['dvd', '-', 'диске']\n"
     ]
    }
   ],
   "source": [
    "from yargy import Parser\n",
    "from yargy.pipelines import morph_pipeline\n",
    "\n",
    "\n",
    "RULE = morph_pipeline([\n",
    "    'dvd-диск',\n",
    "    'видео файл',\n",
    "    'видеофильм',\n",
    "    'газета',\n",
    "    'электронный дневник',\n",
    "    'эссе',\n",
    "])\n",
    "\n",
    "parser = Parser(RULE)\n",
    "text = 'Видео файл на dvd-диске'\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:54.576104Z",
     "start_time": "2020-02-12T14:12:54.511149Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Чеченской', 'республике']\n",
      "['Донецкая', 'народная', 'республика']\n"
     ]
    }
   ],
   "source": [
    "from yargy import Parser, rule, and_\n",
    "from yargy.predicates import gram, is_capitalized, dictionary\n",
    "\n",
    "\n",
    "GEO = rule(\n",
    "    and_(\n",
    "        gram('ADJF'),  # так помечается прилагательное, остальные пометки описаны в\n",
    "                       # http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "        is_capitalized()\n",
    "    ),\n",
    "    gram('ADJF').optional().repeatable(),\n",
    "    dictionary({\n",
    "        'федерация',\n",
    "        'республика'\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "parser = Parser(GEO)\n",
    "text = '''\n",
    "В Чеченской республике на день рождения ...\n",
    "Донецкая народная республика провозгласила ...\n",
    "Башня Федерация — одна из самых высоких ...\n",
    "'''\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:13:57.167613Z",
     "start_time": "2020-02-12T13:13:57.159920Z"
    }
   },
   "source": [
    "### Предикаты\n",
    "\n",
    "Предикат — функция, которая принимает на вход токен и возвращает True или False. В Yargy встроено много готовых предикатов. Полный список есть в справочнике. Предикаты комбинируются с помощью and_, or_ и not_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:17.173350Z",
     "start_time": "2020-02-12T14:12:17.136108Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from yargy import and_, not_\n",
    "from yargy.tokenizer import MorphTokenizer\n",
    "from yargy.predicates import is_capitalized, eq\n",
    "\n",
    "\n",
    "tokenizer = MorphTokenizer()\n",
    "token = next(tokenizer('Стали'))\n",
    "\n",
    "predicate = is_capitalized()\n",
    "print(predicate(token))\n",
    "\n",
    "predicate = and_(\n",
    "    is_capitalized(),\n",
    "    not_(eq('марки'))\n",
    ")\n",
    "print(predicate(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T13:15:56.600763Z",
     "start_time": "2020-02-12T13:15:56.596609Z"
    }
   },
   "source": [
    "### Грамматики\n",
    "В Yargy используется специальный DSL для описания грамматик. Любую контекстно-свободную грамматику можно описать с помощью конструкций Питона. Например, есть примитивная грамматика для размеров одежды:\n",
    "\n",
    "KEY -> р. | размер\n",
    "\n",
    "VALUE -> S | M | L\n",
    "\n",
    "SIZE -> KEY VALUE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:14:21.602988Z",
     "start_time": "2020-02-12T14:14:21.589310Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIZE -> KEY VALUE\n",
       "KEY -> 'р' '.' | 'размер'\n",
       "VALUE -> 'S' | 'M' | 'L' | 'XS'\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yargy import rule, or_\n",
    "\n",
    "\n",
    "KEY = or_(\n",
    "    rule('р', '.'),\n",
    "    rule('размер')\n",
    ").named('KEY')\n",
    "VALUE = or_(\n",
    "    rule('S'),\n",
    "    rule('M'),\n",
    "    rule('L'),\n",
    "    rule('XS'),\n",
    ").named('VALUE')\n",
    "SIZE = rule(\n",
    "    KEY,\n",
    "    VALUE\n",
    ").named('SIZE')\n",
    "SIZE.normalized.as_bnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:14:27.723857Z",
     "start_time": "2020-02-12T14:14:27.662113Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "parser = Parser(\n",
    "    SIZE\n",
    ")\n",
    "text = 'размер M; размер A; размер XS;'\n",
    "for match in parser.findall(text):\n",
    "    print([_.value for _ in match.tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.308726Z",
     "start_time": "2020-02-12T14:12:17.354354Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from yargy import Parser, rule, and_, or_, not_\n",
    "from yargy.interpretation import fact, attribute\n",
    "from yargy.predicates import gram, is_capitalized, dictionary, eq\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.323139Z",
     "start_time": "2020-02-12T14:12:19.310769Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "START = rule(\n",
    "    or_(\n",
    "        rule(gram('ADJF')),\n",
    "        rule(gram('NOUN'))\n",
    "    ).optional(),\n",
    "    gram('NOUN')\n",
    ")\n",
    "\n",
    "START_S = or_(\n",
    "    eq('такой'),\n",
    "    eq('такие'),\n",
    ")\n",
    "\n",
    "KAK = eq('как')\n",
    "INCLUDING = or_(\n",
    "    or_(\n",
    "        eq('в'),\n",
    "        eq('том'),\n",
    "        eq('числе'),\n",
    "    ),\n",
    "    eq('включающий'),\n",
    "    or_(\n",
    "        eq('включающий'),\n",
    "        eq('в'),\n",
    "        eq('себя'),\n",
    "    ),\n",
    "    or_(\n",
    "        eq('включающие'),\n",
    "        eq('в'),\n",
    "        eq('себя'),\n",
    "    ),\n",
    "    eq('включающие'),\n",
    "    eq('особенно'),\n",
    "\n",
    ")\n",
    "\n",
    "MID_S = or_(\n",
    "    rule(\n",
    "        or_(\n",
    "            eq('такой'),\n",
    "            eq('такие'),\n",
    "        ),\n",
    "        eq('как')\n",
    "    )\n",
    ")\n",
    "ATAKJE = rule(\n",
    "    eq(','),\n",
    "    eq('а'),\n",
    "    eq('также')\n",
    ")\n",
    "\n",
    "MID = or_(\n",
    "    rule(\n",
    "        eq('это')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—'),\n",
    "        eq('это')\n",
    "    ),\n",
    "    rule(\n",
    "        eq('—'),\n",
    "        not_(eq('км'))\n",
    "    ),\n",
    "    rule(\n",
    "        or_(\n",
    "            eq('и'),\n",
    "            eq('или'),\n",
    "        ),\n",
    "        eq('другие')\n",
    "    )\n",
    ")\n",
    "\n",
    "END = or_(\n",
    "    rule(\n",
    "        gram('NOUN'),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('ADJF').repeatable(),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('ADJF'),\n",
    "        gram('ADJF').repeatable(),\n",
    "        gram('NOUN')\n",
    "    ),\n",
    "    rule(\n",
    "        gram('NOUN').repeatable(),\n",
    "        gram('ADJF'),\n",
    "        gram('NOUN').repeatable()\n",
    "    ),\n",
    "    rule(\n",
    "        gram('NOUN').repeatable()\n",
    "    )\n",
    ")\n",
    "\n",
    "Item = fact(\n",
    "    'Item',\n",
    "    [attribute('titles').repeatable()]\n",
    ")\n",
    "\n",
    "\n",
    "IGNORE = rule(\n",
    "    '(',\n",
    "    not_(eq(')')).repeatable(),\n",
    "    ')'\n",
    ")\n",
    "\n",
    "ITEM = rule(\n",
    "    IGNORE.interpretation(\n",
    "        Item.titles\n",
    "    ),\n",
    "    eq(',').optional() \n",
    ").repeatable().interpretation(\n",
    "    Item\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:19.434702Z",
     "start_time": "2020-02-12T14:12:19.324707Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_hyperonyms(main_word):\n",
    "    HYPONYM = eq(utils.deaccent(main_word))\n",
    "    RULE = or_(\n",
    "        rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "        rule(HYPONYM, MID, END),\n",
    "        rule(START_S, END, KAK, HYPONYM),\n",
    "        rule(END, INCLUDING, HYPONYM)\n",
    "    )\n",
    "    parser = Parser(RULE) \n",
    "    text = utils.deaccent(wikipedia.summary(main_word))\n",
    "    print(text)\n",
    "    text = re.sub(r'\\(.+?\\)', '', text)\n",
    "    text = text.lower().replace('* сергии радонежскии* ', '')\n",
    "    for idx, match in enumerate(parser.findall(text.lower())):\n",
    "        k = [_.value for _ in match.tokens]\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T14:12:22.648500Z",
     "start_time": "2020-02-12T14:12:19.437840Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "get_hyperonyms(\"банан\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1 (deadline 19.02.2020 24:00)\n",
    "* Find your name on the spreadsheet https://docs.google.com/spreadsheets/d/1RR2I6toCkebbGU1UK83HS70Ru_l0_o-nnZIHyiFB0No/edit?usp=sharing. In opposite of your name there are 24 words of hyponyms, you have to insert five corresponding hypernyms next to them. Examples of hyponyms and hyperonyms relationship you can find above in the current Jupiter notebook.\n",
    "* Find for each pair of hyponyms and hypernyms a corresponding snippet of a text with their mentions. The source of the text can be any free resources, e.g., Wikipedia, Google, Yandex, others. You should save the snippets and their URLs within the lab2 folder in your NLP git-repo with .csv file-extension in a single file.\n",
    "\n",
    "#### Task 2 (deadline 26.02.2020 24:00)\n",
    "* It would be best if you created a pandas DataFrame of the texts from the previous task. And apply to the DataFrame the function 'get_hyperonyms,' which must return the list of the corresponding hypernyms from the text automatically. If there are errors or misses, you should fix them in the code for your case of the 24 words. Nevertheless, it is strictly prohibited to use hard coding. Save your notebook with parser code within the lab2 folder in your NLP git-repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# homework_data = pd.read_csv('words_2.csv')\n",
    "\n",
    "# homework_data\n",
    "\n",
    "\n",
    "# # for key in keys:\n",
    "# #     for word in \n",
    "\n",
    "# # for row in homework_data.iterrows():\n",
    "# #     print(row[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_text(word): \n",
    "#     return utils.deaccent(wikipedia.summary(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# # Search in wiki only HYPERONYMs\n",
    "# for hypo, hypers in zip(list(homework_data['HYPONYM']), list(homework_data['HYPERONYM'])):\n",
    "#     hypers = list(map(lambda x: x.strip(), hypers.split(\", \")))\n",
    "#     for hyper in hypers:\n",
    "#         tmp = {}\n",
    "#         tmp[\"hypo\"] = hypo\n",
    "#         if hyper == \"\":\n",
    "#             continue\n",
    "#         tmp[\"key\"] = hyper\n",
    "#         try:\n",
    "#             tmp[\"text\"] = find_text(hyper)\n",
    "#         except:\n",
    "#             tmp[\"text\"] = \"\"\n",
    "#             print(\"error\")\n",
    "#         result.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# csv_file = \"text_HYPONYM.csv\"\n",
    "# try:\n",
    "#     with open(csv_file, 'w') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=[\"hypo\", \"key\", \"text\"])\n",
    "#         for data in result:\n",
    "#             writer.writerow(data)\n",
    "# except IOError:\n",
    "#     print(\"I/O error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_hyperonyms2(main_word, text):\n",
    "#     HYPONYM = eq(utils.deaccent(main_word))\n",
    "#     RULE = or_(\n",
    "#         rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "#         rule(HYPONYM, MID, END),\n",
    "#         rule(START_S, END, KAK, HYPONYM),\n",
    "#         rule(END, INCLUDING, HYPONYM)\n",
    "#     )\n",
    "#     parser = Parser(RULE) \n",
    "# #     text = utils.deaccent(wikipedia.summary(main_word))\n",
    "# #     print(text)\n",
    "#     text = re.sub(r'\\(.+?\\)', '', text)\n",
    "# #     text = text.lower().replace('* сергии радонежскии* ', '')\n",
    "#     for idx, match in enumerate(parser.findall(text.lower())):\n",
    "#         k = [_.value for _ in match.tokens]\n",
    "#         print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# for data in result:\n",
    "#     print('Гиперонимы для слова: ', data[\"key\"])\n",
    "#     if data[\"text\"] == \"\":\n",
    "#         print(\"Пусто\")\n",
    "#         continue\n",
    "#     print('\\n')\n",
    "#     get_hyperonyms2(data[\"key\"], data[\"text\"])\n",
    "#     print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google import google\n",
    "\n",
    "class GoogleSearch(object):\n",
    "    def __init__(self, hypo, hyper, num_page):\n",
    "        self.hypo = hypo\n",
    "        self.hyper = hyper\n",
    "        self.num_page = num_page\n",
    "        self.res = []\n",
    "        \n",
    "    def get_text(self):\n",
    "        if  len(self.res) > 0:\n",
    "            return \"\\n\".join(list(map(lambda x: str(x.description), self.res)))\n",
    "        return None\n",
    "    \n",
    "    def get_link(self):\n",
    "        if  len(self.res) > 0:\n",
    "            return \"\\n\".join(list(map(lambda x: str(x.link), self.res)))\n",
    "        return None\n",
    "    \n",
    "    def get_google_link(self):\n",
    "        if  len(self.res) > 0:\n",
    "            return \"\\n\".join(list(map(lambda x: str(x.google_link), self.res)))\n",
    "        return None\n",
    "    \n",
    "    def find_text(self):\n",
    "        search_results = google.search(self.hypo + \" \" + self.hyper, self.num_page)\n",
    "        print(self.hypo + \" \" + self.hyper)\n",
    "        print(\"Search result count: \", len(search_results))\n",
    "        for res in search_results:\n",
    "            parser = HyperParser(self.hypo, self.hyper, res.description)\n",
    "            parser.get_hyperonyms3()            \n",
    "            if len(parser.hyper_text) > 0: \n",
    "                self.res.append(res)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HyperParser(object):\n",
    "    def __init__(self, hypo, hyper, text):\n",
    "        self.hypo = hypo.capitalize()\n",
    "        self.hyper = hyper\n",
    "        self.text = text\n",
    "        self.hyper_text = []\n",
    "        \n",
    "    def get_hyperonyms3(self):\n",
    "        HYPONYM = eq(utils.deaccent(self.hyper))\n",
    "        RULE = or_(\n",
    "            rule(HYPONYM, ATAKJE, START, MID, END),\n",
    "            rule(HYPONYM, MID, END),\n",
    "            rule(START_S, END, KAK, HYPONYM),\n",
    "            rule(END, INCLUDING, HYPONYM),\n",
    "            rule(HYPONYM, MID, START, START),\n",
    "            rule(HYPONYM, MID, START),\n",
    "            rule(HYPONYM, END)\n",
    "        )\n",
    "        parser = Parser(RULE) \n",
    "        _text = re.sub(r'\\(.+?\\)', '', utils.deaccent(self.text))\n",
    "        for idx, match in enumerate(parser.findall(_text.lower())):\n",
    "            k = [_.value for _ in match.tokens]\n",
    "            if k is not None:\n",
    "                print(k)\n",
    "                self.hyper_text.append(k)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ГЕККОН ящерица\n",
      "Search result count:  9\n",
      "['ящерица', 'из', 'семеиства', 'гекконов']\n",
      "['ящерица', 'рептилия', 'животных', 'зеленыи', 'тварь']\n",
      "['ящерица', 'геккона']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'None\\nNone\\nNone'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = GoogleSearch(\"ГЕККОН\", \"ящерица\", 1)\n",
    "tmp.find_text()\n",
    "tmp.get_text()\n",
    "tmp.get_link()\n",
    "tmp.get_google_link()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ГЕККОН ящерица\n",
      "Search result count:  9\n",
      "['ящерица', 'из', 'семеиства', 'гекконов']\n",
      "['ящерица', 'рептилия', 'животных', 'зеленыи', 'тварь']\n",
      "['ящерица', 'геккона']\n",
      "ГЕККОН чешуйчатый\n",
      "Search result count:  9\n",
      "['чешуичатыи', 'покров', 'головы', 'средиземноморского', 'геккона']\n",
      "['чешуичатыи', 'покров', 'головы', 'средиземноморского', 'геккона']\n",
      "ГЕККОН пресмыкающиеся\n",
      "Search result count:  7\n",
      "ГЕККОН животное\n",
      "Search result count:  8\n",
      "['животное', 'под']\n",
      "ГЕККОН рептилия\n",
      "Search result count:  0\n",
      "ГЕЛЬ желеобразное вещество\n",
      "Search result count:  9\n",
      "ГЕЛЬ косметика\n",
      "Search result count:  9\n",
      "['косметика', 'алоэ']\n",
      "['косметика', 'гель', 'алоэ']\n",
      "['косметика', 'в', 'украине']\n",
      "ГЕОРГИН растение\n",
      "Search result count:  10\n",
      "['растение', 'георгина', 'в', 'честь', 'известного', 'ботаника']\n",
      "['растение', 'с']\n",
      "['растение', 'с']\n",
      "ГЕОРГИН цветы\n",
      "Search result count:  8\n",
      "['цветы', 'георгины', 'семеиства']\n",
      "['цветы', 'георгины']\n",
      "['цветы', 'георгины']\n",
      "ГЕОРГИН сложноцветный цветок\n",
      "Search result count:  9\n",
      "ГЕОРГИН трава\n",
      "Search result count:  0\n",
      "ГЕОРГИН зелень\n",
      "Search result count:  9\n",
      "['зелень', 'хвоиников']\n",
      "ГЕОФАК факультет\n",
      "Search result count:  10\n",
      "['факультет', 'мгу', 'имени', 'м']\n",
      "['факультет', 'географии', 'и', 'природопользования']\n",
      "['факультет', 'мпгу']\n",
      "['факультет', 'белградского', 'университета']\n",
      "['факультет', 'мгу']\n",
      "ГЕОФАК направление подготовки\n",
      "Search result count:  10\n",
      "ГЕОФАК специальность\n",
      "Search result count:  10\n",
      "['специальность', 'география']\n",
      "['специальность', 'высшего', 'образования']\n",
      "ГЕОФАК структурное подразделение\n",
      "Search result count:  10\n",
      "ГЕОФАК департамент\n",
      "Search result count:  10\n",
      "['департамент', 'кадровои', 'работы']\n",
      "ГЕРИАТРИЯ геронтология\n",
      "Search result count:  10\n",
      "['геронтология', 'и', 'гериатрия']\n",
      "['геронтология', 'и', 'гериатрия', 'в', 'россии']\n",
      "['геронтология', 'и', 'гериатрия', 'в', 'россии']\n",
      "['геронтология', 'и', 'гериатрия']\n",
      "ГЕРИАТРИЯ наука\n",
      "Search result count:  10\n",
      "['наука', 'поиск', 'диссертации', 'наити']\n",
      "ГЕРИАТРИЯ изучение болезней\n",
      "Search result count:  10\n",
      "ГЕРИАТРИЯ знание\n",
      "Search result count:  10\n",
      "['знание', 'основ', 'организации', 'сестринского', 'дела']\n",
      "ГЕРИАТРИЯ лечение\n",
      "Search result count:  10\n",
      "['лечение', 'артериальнои', 'гипертонии']\n",
      "ГЕРМАНИЗАЦИЯ распространение языка\n",
      "Search result count:  10\n",
      "ГЕРМАНИЗАЦИЯ распространения культуры\n",
      "Search result count:  10\n",
      "ГЕРМЕТИК паста\n",
      "Search result count:  8\n",
      "['паста', 'герметик']\n",
      "['паста', 'герметик']\n",
      "['паста', 'герметик']\n",
      "['паста', 'герметик']\n",
      "['паста', 'герметик']\n",
      "ГЕРМЕТИК материал\n",
      "Search result count:  10\n",
      "['материал', 'из', 'википедии']\n",
      "['материал', 'из', 'википедии']\n",
      "['материал', 'пастообразнои']\n",
      "ГЕРМЕТИК смазка\n",
      "Search result count:  9\n",
      "['смазка', 'герметик']\n",
      "ГЕРМЕТИК замазка\n",
      "Search result count:  9\n",
      "ГЕРОНТОЛОГ врач\n",
      "Search result count:  0\n",
      "ГЕРОНТОЛОГ специалист\n",
      "Search result count:  10\n",
      "ГЕРОНТОЛОГ доктор\n",
      "Search result count:  10\n",
      "['доктор', 'медицинских', 'наук']\n",
      "['доктор', 'медицинских', 'наук']\n",
      "['доктор', 'медицинских', 'наук']\n",
      "['доктор', 'медицинских', 'наук']\n",
      "['доктор', 'медицинских', 'наук']\n",
      "ГЕРОНТОЛОГ человек\n",
      "Search result count:  10\n",
      "ГЕРОНТОЛОГ профессия\n",
      "Search result count:  10\n",
      "['профессия', 'сестры']\n",
      "ГЕСТАПОВЕЦ сотрудник гестапо\n",
      "Search result count:  10\n",
      "ГЕСТАПОВЕЦ человек\n",
      "Search result count:  0\n",
      "ГЕСТАПОВЕЦ тайная военная полиция\n",
      "Search result count:  0\n",
      "ГЕСТАПОВЕЦ эсэсовец\n",
      "Search result count:  10\n",
      "['эсэсовец', 'хаинц', 'фельфе']\n",
      "ГЕСТАПОВЕЦ профессия\n",
      "Search result count:  10\n",
      "ГИГИЕНИСТ человек\n",
      "Search result count:  10\n",
      "ГИГИЕНИСТ врач\n",
      "Search result count:  0\n",
      "ГИГИЕНИСТ специалист\n",
      "Search result count:  10\n",
      "['специалист', 'и', 'кому', 'его', 'услуги']\n",
      "['специалист', '—', 'гигиенист']\n",
      "ГИГИЕНИСТ доктор\n",
      "Search result count:  10\n",
      "ГИГИЕНИСТ профессия\n",
      "Search result count:  9\n",
      "['профессия', 'гигиенист']\n",
      "['профессия', 'врача', 'гигиениста']\n",
      "ГИДРАТАЦИЯ сольватация\n",
      "Search result count:  10\n",
      "['сольватация', '—', 'электростатическое', 'взаимодеиствие']\n",
      "['сольватация', 'ионов', 'в', 'растворе']\n",
      "['сольватация', 'ионов', 'в', 'водных', 'растворах', 'в', 'связи']\n",
      "ГИДРАТАЦИЯ соединение\n",
      "Search result count:  10\n",
      "ГИДРИД соединение водорода с металлами\n",
      "Search result count:  0\n",
      "ГИДРИД химический элемент\n",
      "Search result count:  10\n",
      "ГИДРОЛИЗ разложение\n",
      "Search result count:  10\n",
      "['разложение', 'водои']\n",
      "['разложение', 'галидов']\n",
      "ГИДРОЛИЗ сольволиз\n",
      "Search result count:  10\n",
      "['сольволиз', '—', 'реакция', 'обменного', 'разложения']\n",
      "['сольволиз', 'в', 'воде']\n",
      "['сольволиз', 'в', 'аммиаке']\n",
      "['сольволиз', 'и', 'гидролиз']\n",
      "['сольволиз', 'в', 'воде']\n",
      "['сольволиз', 'в', 'аммиаке']\n",
      "['сольволиз', 'в', 'спиртах']\n",
      "['сольволиз', 'и', 'гидролиз']\n",
      "ГИДРОПОНИКА рост\n",
      "Search result count:  8\n",
      "['рост', 'растении', 'и']\n",
      "['рост', 'корня']\n",
      "['рост', 'растении']\n",
      "['рост', 'корнеи', 'в', 'гидропоннои', 'установке']\n",
      "ГИДРОПОНИКА выращивание растений\n",
      "Search result count:  9\n",
      "ГИДРОЦИКЛ транспорт\n",
      "Search result count:  10\n",
      "['транспорт', 'в', 'атырау']\n",
      "['транспорт', 'и', 'коммуникации']\n",
      "ГИДРОЦИКЛ мотоцикл\n",
      "Search result count:  9\n",
      "ГИДРОЦИКЛ аквабайк\n",
      "Search result count:  9\n",
      "['аквабаик', '—', 'общее', 'название']\n",
      "ГИДРОЦИКЛ авто\n",
      "Search result count:  10\n",
      "['авто', 'в', 'казахстане']\n",
      "ГИДРОЦИКЛ водные лыжи\n",
      "Search result count:  8\n",
      "ГИПЕРБОЛА график\n",
      "Search result count:  8\n",
      "['график', 'функции', 'вида']\n",
      "['график', 'функции']\n",
      "['график', 'функции']\n",
      "['график', 'гиперболы']\n",
      "['график', 'функции']\n",
      "['график', 'функции', 'гиперболы']\n",
      "ГИПЕРБОЛА кривая\n",
      "Search result count:  10\n",
      "ГИПЕРБОЛА геометрия\n",
      "Search result count:  10\n",
      "ГИПЕРКАР авто\n",
      "Search result count:  9\n",
      "ГИПЕРКАР машина\n",
      "Search result count:  9\n",
      "ГИПЕРКАР транспорт\n",
      "Search result count:  8\n",
      "['транспорт', 'электромобили', 'япония', 'видео', 'рекорд']\n",
      "ГИПЕРКАР суперкар\n",
      "Search result count:  9\n",
      "['суперкар', 'и', 'гиперкар']\n",
      "ГИПЕРКАР средство передвижения\n",
      "Search result count:  9\n",
      "ГИПЕРРЕАЛИЗМ направление в исскустве\n",
      "Search result count:  9\n",
      "ГИПЕРРЕАЛИЗМ современное исскуство\n",
      "Search result count:  0\n",
      "ГИПЕРРЕАЛИЗМ исскуство\n",
      "Search result count:  9\n",
      "ГИПЕРРЕАЛИЗМ натурализм\n",
      "Search result count:  9\n",
      "['натурализм', '—', 'направление', 'в', 'сценическом', 'искусстве']\n",
      "['натурализм', 'и', 'прагматизм', 'гиперреализм']\n",
      "['натурализм', 'и', 'прагматизм', 'гиперреализм']\n",
      "ГИПЕРРЕАЛИЗМ живопись\n",
      "Search result count:  9\n",
      "ГИПЕРТЕРМИЯ перегревание\n",
      "Search result count:  10\n",
      "['перегревание', 'тела', 'человека']\n",
      "['перегревание', 'организма']\n",
      "['перегревание', 'тела', 'человека']\n",
      "['перегревание', 'организма']\n",
      "['перегревание', 'тела']\n",
      "ГИПЕРТЕРМИЯ повышение температуры тела\n",
      "Search result count:  10\n",
      "ГИПЕРТЕРМИЯ накопление тепла\n",
      "Search result count:  10\n",
      "ГИПЕРТЕРМИЯ лечение\n",
      "Search result count:  10\n",
      "['лечение', 'пациентов', 'с', 'центрогеннои', 'лихорадкои', 'с', 'применением']\n",
      "['лечение', 'гипертермии']\n",
      "ГИПЕРТЕРМИЯ терапия\n",
      "Search result count:  10\n",
      "['терапия', 'и', 'химиотерапия']\n",
      "['терапия', 'лихорадки', 'и', 'гипертермии']\n",
      "ГИПЕРТРОФИЯ увеличение органа\n",
      "Search result count:  0\n",
      "ГИПЕРТРОФИЯ рост органа\n",
      "Search result count:  9\n",
      "ГИПЕРТРОФИЯ болезнь\n",
      "Search result count:  0\n",
      "ГИПОТОНИК больной\n",
      "Search result count:  10\n",
      "['больнои', 'с']\n",
      "ГИПОТОНИК человек\n",
      "Search result count:  10\n",
      "['человек', 'при']\n",
      "ГИПОТОНИК пациент\n",
      "Search result count:  10\n",
      "['пациент', 'при', 'цифрах']\n",
      "['пациент', 'при', 'пониженном', 'давлении']\n",
      "ГИПЮР ткань\n",
      "Search result count:  9\n",
      "['ткань', 'с']\n",
      "['ткань', 'гипюр']\n",
      "['ткань', 'гипюр', 'в', 'интернет']\n",
      "['ткань', 'в', 'виде']\n",
      "['ткань', 'онлаин']\n",
      "['ткань', 'гипюр', 'с', 'фото']\n",
      "ГИПЮР материал\n",
      "Search result count:  9\n",
      "ГИПЮР кружева\n",
      "Search result count:  0\n",
      "ГИРЯ спорт товар\n",
      "Search result count:  9\n",
      "ГИРЯ предмет\n",
      "Search result count:  9\n",
      "['предмет', 'заданнои', 'массы']\n",
      "['предмет', 'заданнои', 'массы']\n",
      "['предмет', 'знаком']\n",
      "['предмет', 'заданнои', 'массы']\n",
      "ГИРЯ металлический груз\n",
      "Search result count:  10\n",
      "ГИЧКА шлюпка\n",
      "Search result count:  9\n",
      "['шлюпка', 'с']\n",
      "['шлюпка', 'с']\n",
      "['шлюпка', 'с', 'острым', 'носом', 'и', 'транцевои', 'кормои']\n",
      "['шлюпка', 'с', 'острым', 'носом', 'и']\n",
      "ГИЧКА судно\n",
      "Search result count:  9\n",
      "['судно', 'с', 'распашными', 'веслами']\n",
      "['судно', 'небольших', 'размеров']\n",
      "ГИЧКА лодка\n",
      "Search result count:  10\n",
      "['лодка', 'проекта']\n",
      "ГИЧКА транспорт\n",
      "Search result count:  9\n",
      "['транспорт', 'сибирскои', 'флотилии', 'россииского']\n",
      "['транспорт', 'подоидет', 'в', 'тои']\n",
      "ГИЧКА средство передвижения\n",
      "Search result count:  9\n"
     ]
    }
   ],
   "source": [
    "homework_data = pd.read_csv('words_2.csv')\n",
    "\n",
    "homework_data\n",
    "\n",
    "result = []\n",
    "for hypo, hypers in zip(list(homework_data['HYPONYM']), list(homework_data['HYPERONYM'])):\n",
    "    hypers = list(map(lambda x: x.strip(), hypers.split(\", \")))\n",
    "    for hyper in hypers:\n",
    "        tmp = {}\n",
    "        pair = hypo + \" \" + hyper\n",
    "        tmp[\"hypo\"] = hypo\n",
    "        if hyper == \"\":\n",
    "            continue\n",
    "        tmp[\"key\"] = hyper\n",
    "        search = GoogleSearch(hypo, hyper, 1)\n",
    "        try:\n",
    "            search.find_text()\n",
    "            if search.get_text() is not None:\n",
    "                tmp[\"text\"] = search.get_text()\n",
    "                tmp[\"link\"] = search.get_link()\n",
    "                tmp[\"google_link\"] = search.get_google_link()                \n",
    "        except Exception as err:\n",
    "            tmp[\"text\"] = \"\"\n",
    "            tmp[\"link\"] = search.get_link()\n",
    "            tmp[\"google_link\"] = search.get_google_link()                \n",
    "            print(pair)\n",
    "            print(err)\n",
    "        result.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hypo': 'ГЕККОН',\n",
       " 'key': 'ящерица',\n",
       " 'text': 'Геккон токи (лат. Gekko gecko) — ящерица из семейства гекконов. Содержание. 1 Описание; 2 Ареал и места обитания; 3 Питание; 4 Размножение\\xa0...\\nОчистить фильтры. Похожие изображения: ящерица рептилия животных зеленый тварь. 376 Бесплатные фото Геккон. Геккон, Рептилия, Террариум\\xa0...\\nСкачать стоковое фото ящерица геккона ✓ популярный фотобанк ✓ доступные цены ✓ миллионы роялти-фри фотографий, изображений и картинок в\\xa0...',\n",
       " 'link': 'https://ru.wikipedia.org/wiki/%D0%93%D0%B5%D0%BA%D0%BA%D0%BE%D0%BD_%D1%82%D0%BE%D0%BA%D0%B8\\nhttps://pixabay.com/ru/photos/search/%D0%B3%D0%B5%D0%BA%D0%BA%D0%BE%D0%BD/\\nhttps://ru.depositphotos.com/stock-photos/%D1%8F%D1%89%D0%B5%D1%80%D0%B8%D1%86%D0%B0-%D0%B3%D0%B5%D0%BA%D0%BA%D0%BE%D0%BD%D0%B0.html',\n",
       " 'google_link': 'None\\nNone\\nNone'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "csv_file = \"text_HYPONYM.csv\"\n",
    "try:\n",
    "    with open(csv_file, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=[\"hypo\", \"key\", \"text\", \"link\", \"google_link\"])\n",
    "        for data in result:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
